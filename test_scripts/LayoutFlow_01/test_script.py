#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import torch
import numpy as np
import json
import argparse
from typing import Dict, List, Optional, Tuple, Union
import sys
from datetime import datetime

# ç”¨äºåºåˆ—åŒ–Tensoråˆ°JSON
class TensorEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, torch.Tensor):
            return obj.tolist()
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return super(TensorEncoder, self).default(obj)

# ä»ä¸­å¿ƒç‚¹åæ ‡è½¬æ¢ä¸ºå·¦ä¸Šå³ä¸‹åæ ‡
def convert_xywh_to_ltrb(bbox):
    """Convert from center format (x, y, w, h) to corner format (l, t, r, b)"""
    if isinstance(bbox, np.ndarray):
        lib = np
    else:
        lib = torch
    
    if bbox.dim() == 2:  # [N, 4]
        xc, yc, w, h = bbox[:, 0], bbox[:, 1], bbox[:, 2], bbox[:, 3]
        x1 = xc - w / 2
        y1 = yc - h / 2
        x2 = xc + w / 2
        y2 = yc + h / 2
        return torch.stack([x1, y1, x2, y2], dim=1)
    elif bbox.dim() == 3:  # [B, N, 4]
        xc, yc, w, h = bbox[:, :, 0], bbox[:, :, 1], bbox[:, :, 2], bbox[:, :, 3]
        x1 = xc - w / 2
        y1 = yc - h / 2
        x2 = xc + w / 2
        y2 = yc + h / 2
        return torch.stack([x1, y1, x2, y2], dim=2)
    else:
        # å¤„ç†ç‰¹æ®Šæƒ…å†µ
        xc, yc, w, h = bbox[0], bbox[1], bbox[2], bbox[3]
        x1 = xc - w / 2
        y1 = yc - h / 2
        x2 = xc + w / 2
        y2 = yc + h / 2
        return torch.stack([x1, y1, x2, y2])

# è®¡ç®—å¸ƒå±€çš„å¯¹é½åº¦
def compute_alignment(bbox, mask, format='xywh', output_torch=False):
    """è®¡ç®—å¸ƒå±€çš„å¯¹é½åº¦
    
    å‚æ•°:
        bbox: [B, N, 4] çš„å¼ é‡ï¼ŒåŒ…å«å¸ƒå±€çš„è¾¹ç•Œæ¡†åæ ‡
        mask: [B, N] çš„å¸ƒå°”å¼ é‡ï¼Œè¡¨ç¤ºæœ‰æ•ˆå…ƒç´ 
        format: åæ ‡æ ¼å¼ï¼Œ'xywh'è¡¨ç¤ºä¸­å¿ƒç‚¹åæ ‡ï¼Œ'ltrb'è¡¨ç¤ºå·¦ä¸Šå³ä¸‹åæ ‡
        output_torch: æ˜¯å¦è¿”å›torchå¼ é‡
        
    è¿”å›:
        å¯¹é½åº¦åˆ†æ•° (å€¼è¶Šå°è¡¨ç¤ºå¯¹é½åº¦è¶Šå¥½)
    """
    bbox = bbox.permute(2, 0, 1)  # [4, B, N]
    if format == 'xywh':
        # è½¬æ¢ä¸ºå·¦ä¸Šå³ä¸‹åæ ‡
        xl, yt, xr, yb = convert_xywh_to_ltrb(bbox.permute(1, 2, 0)).permute(2, 0, 1)
    elif format == 'ltrb':
        xl, yt, xr, yb = bbox
    else:
        print(f'{format}æ ¼å¼ä¸æ”¯æŒ.')
        return None
    
    # è®¡ç®—ä¸­å¿ƒç‚¹åæ ‡
    xc = (xr + xl) / 2
    yc = (yt + yb) / 2
    
    # æ”¶é›†æ‰€æœ‰å‚è€ƒçº¿ï¼ˆå·¦/ä¸­/å³ï¼Œä¸Š/ä¸­/ä¸‹ï¼‰
    X = torch.stack([xl, xc, xr, yt, yc, yb], dim=1)  # [B, 6, N]
    
    # è®¡ç®—æ¯ä¸ªå…ƒç´ åˆ°å…¶ä»–æ‰€æœ‰å…ƒç´ æ‰€æœ‰å‚è€ƒçº¿çš„è·ç¦»
    X = X.unsqueeze(-1) - X.unsqueeze(-2)  # [B, 6, N, N]
    
    # å°†è‡ªå·±ä¸è‡ªå·±çš„è·ç¦»è®¾ç½®ä¸º1ï¼ˆä¸è€ƒè™‘ï¼‰
    idx = torch.arange(X.size(2), device=X.device)
    X[:, :, idx, idx] = 1.
    
    # è®¡ç®—è·ç¦»çš„ç»å¯¹å€¼ï¼Œå¹¶é‡æ–°æ’åˆ—ç»´åº¦
    X = X.abs().permute(0, 2, 1, 3)  # [B, N, 6, N]
    
    # æ— æ•ˆå…ƒç´ çš„è·ç¦»è®¾ä¸º1ï¼ˆä¸è€ƒè™‘ï¼‰
    X[~mask] = 1.
    
    # å¯¹äºæ¯ä¸ªå…ƒç´ ï¼Œæ‰¾åˆ°æœ€æ¥è¿‘å…¶ä»–å…ƒç´ çš„å‚è€ƒçº¿çš„æœ€å°è·ç¦»
    X = X.min(-1).values.min(-1).values  # [B, N]
    
    # ç§»é™¤è·ç¦»ä¸º1çš„å€¼ï¼ˆè‡ªå·±åˆ°è‡ªå·±çš„è·ç¦»æˆ–æ— æ•ˆå…ƒç´ ï¼‰
    X.masked_fill_(X.eq(1.), 0.)
    
    # å˜æ¢è·ç¦»ä¸ºå¯¹é½åˆ†æ•°ï¼š-log(1-d)ï¼Œè·ç¦»è¶Šå°ï¼Œåˆ†æ•°è¶Šå°
    X = -torch.log(1 - X)
    
    # è®¡ç®—å¹³å‡å¯¹é½åˆ†æ•°
    if not output_torch:
        score = torch.from_numpy(np.nan_to_num((X.sum(-1) / mask.float().sum(-1)))).numpy()
    else:
        score = torch.nan_to_num(X.sum(-1) / mask.float().sum(-1))
    
    return score.mean().item()

# ä»JSONæ–‡ä»¶åŠ è½½å¸ƒå±€æ•°æ®
def load_layout_data(file_path):
    """ä»JSONæ–‡ä»¶åŠ è½½å¸ƒå±€æ•°æ®"""
    try:
        with open(file_path, 'r') as f:
            data = json.load(f)
        
        # å°†åˆ—è¡¨è½¬æ¢ä¸ºtensor
        if 'bbox' in data:
            data['bbox'] = torch.tensor(data['bbox'])
        if 'ltrb_bbox' in data:
            data['ltrb_bbox'] = torch.tensor(data['ltrb_bbox'])
        if 'label' in data:
            data['label'] = torch.tensor(data['label'])
        if 'pad_mask' in data:
            data['pad_mask'] = torch.tensor(data['pad_mask'], dtype=torch.bool)
        
        return data
    except Exception as e:
        print(f"åŠ è½½æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        return None

# è®¡ç®—é‡å ç‡
def compute_overlap(bbox, mask, format='xywh'):
    """è®¡ç®—å¸ƒå±€å…ƒç´ ä¹‹é—´çš„é‡å ç‡
    
    å‚æ•°:
        bbox: [B, N, 4] çš„å¼ é‡ï¼ŒåŒ…å«å¸ƒå±€çš„è¾¹ç•Œæ¡†åæ ‡
        mask: [B, N] çš„å¸ƒå°”å¼ é‡ï¼Œè¡¨ç¤ºæœ‰æ•ˆå…ƒç´ 
        format: åæ ‡æ ¼å¼ï¼Œ'xywh'è¡¨ç¤ºä¸­å¿ƒç‚¹åæ ‡ï¼Œ'ltrb'è¡¨ç¤ºå·¦ä¸Šå³ä¸‹åæ ‡
        
    è¿”å›:
        é‡å ç‡åˆ†æ•° (å€¼è¶Šå°è¡¨ç¤ºé‡å è¶Šå°‘)
    """
    # å°†æ— æ•ˆå…ƒç´ çš„åæ ‡ç½®ä¸º0
    bbox = bbox.masked_fill(~mask.unsqueeze(-1), 0)
    bbox = bbox.permute(2, 0, 1)  # [4, B, N]

    if format == 'xywh':
        # è½¬æ¢ä¸ºå·¦ä¸Šå³ä¸‹åæ ‡
        l1, t1, r1, b1 = convert_xywh_to_ltrb(bbox.unsqueeze(-1))
        l2, t2, r2, b2 = convert_xywh_to_ltrb(bbox.unsqueeze(-2))
    elif format == 'ltrb':
        l1, t1, r1, b1 = bbox.unsqueeze(-1)
        l2, t2, r2, b2 = bbox.unsqueeze(-2)
    else:
        print(f'{format}æ ¼å¼ä¸æ”¯æŒ.')
        return None

    # è®¡ç®—æ¯ä¸ªæ¡†çš„é¢ç§¯
    a1 = (r1 - l1) * (b1 - t1)  # [4, B, N, 1]

    # è®¡ç®—äº¤é›†
    l_max = torch.maximum(l1, l2)
    r_min = torch.minimum(r1, r2)
    t_max = torch.maximum(t1, t2)
    b_min = torch.minimum(b1, b2)
    cond = (l_max < r_min) & (t_max < b_min)
    ai = torch.where(cond, (r_min - l_max) * (b_min - t_max),
                     torch.zeros_like(a1[0]))  # [B, N, N]

    # ä¸è€ƒè™‘è‡ªå·±ä¸è‡ªå·±çš„é‡å 
    diag_mask = torch.eye(a1.size(1), dtype=torch.bool,
                        device=a1.device)
    ai = ai.masked_fill(diag_mask, 0)

    # è®¡ç®—äº¤é›†ä¸ç¬¬ä¸€ä¸ªæ¡†é¢ç§¯çš„æ¯”ç‡
    ar = ai / a1
    ar = torch.from_numpy(np.nan_to_num(ar.numpy()))
    
    # è®¡ç®—å¹³å‡é‡å ç‡
    score = torch.from_numpy(
        np.nan_to_num((ar.sum(dim=(1, 2)) / mask.float().sum(-1)).numpy())
    )
    return score.mean().item()

def evaluate_layout(input_file):
    """è¯„ä¼°å¸ƒå±€è´¨é‡
    
    å‚æ•°:
        input_file: è¾“å…¥JSONæ–‡ä»¶è·¯å¾„
    
    è¿”å›:
        åŒ…å«è¯„ä¼°ç»“æœçš„å­—å…¸
    """
    process_status = True
    final_result_status = False
    comments = []
    
    # æ—¶é—´æˆ³
    time_point = datetime.now().isoformat()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(input_file) or os.path.getsize(input_file) == 0:
        comments.append(f"é”™è¯¯ï¼šå¸ƒå±€æ–‡ä»¶ '{input_file}' ä¸å­˜åœ¨æˆ–ä¸ºç©ºã€‚")
        process_status = False
    
    if process_status:
        try:
            # åŠ è½½å¸ƒå±€æ•°æ®
            layouts = load_layout_data(input_file)
            if layouts is None:
                comments.append(f"é”™è¯¯ï¼šåŠ è½½å¸ƒå±€æ•°æ®å¤±è´¥ã€‚")
                process_status = False
            else:
                # è®¡ç®—å¯¹é½åº¦
                alignment_score = compute_alignment(layouts['bbox'], layouts['pad_mask'])
                
                # è®¡ç®—é‡å ç‡
                overlap_score = compute_overlap(layouts['bbox'], layouts['pad_mask'])
                
                # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
                num_layouts = layouts['bbox'].shape[0]
                
                # è®¡ç®—æ¯ä¸ªå¸ƒå±€çš„å…ƒç´ æ•°é‡
                element_counts = layouts['pad_mask'].sum(dim=1).tolist()
                avg_elements = sum(element_counts) / len(element_counts)
                
                # è®¡ç®—ç±»åˆ«åˆ†å¸ƒ
                valid_labels = []
                for i in range(layouts['label'].shape[0]):
                    mask = layouts['pad_mask'][i]
                    valid_labels.extend(layouts['label'][i][mask].tolist())
                
                label_counts = {}
                for l in valid_labels:
                    label_counts[int(l)] = label_counts.get(int(l), 0) + 1
                
                # è¯„ä¼°æ ‡å‡†
                alignment_satisfied = alignment_score < 2.0 # å¯¹é½åº¦åˆ†æ•°é˜ˆå€¼ï¼ˆç¤ºä¾‹ï¼‰
                overlap_satisfied = overlap_score < 0.1    # é‡å ç‡åˆ†æ•°é˜ˆå€¼ï¼ˆç¤ºä¾‹ï¼‰
                
                comments.append(f"ğŸ“Š å¸ƒå±€æ•°é‡: {num_layouts}")
                comments.append(f"ğŸ“ å¯¹é½åº¦åˆ†æ•°: {alignment_score:.4f} (è¶Šå°è¶Šå¥½)")
                comments.append(f"ğŸ” é‡å ç‡åˆ†æ•°: {overlap_score:.4f} (è¶Šå°è¶Šå¥½)")
                comments.append(f"ğŸ“ˆ å¹³å‡å…ƒç´ æ•°é‡: {avg_elements:.2f}")
                comments.append(f"ğŸ¯ å¯¹é½åº¦ < 2.0: {'âœ… æ»¡è¶³' if alignment_satisfied else 'âŒ ä¸æ»¡è¶³'}")
                comments.append(f"ğŸ¯ é‡å ç‡ < 0.1: {'âœ… æ»¡è¶³' if overlap_satisfied else 'âŒ ä¸æ»¡è¶³'}")
                
                final_result_status = alignment_satisfied and overlap_satisfied
                comments.append(f"æœ€ç»ˆè¯„ä¼°ç»“æœï¼šå¯¹é½åº¦æ»¡è¶³={alignment_satisfied}, é‡å ç‡æ»¡è¶³={overlap_satisfied}")
                
                # è¯¦ç»†æŒ‡æ ‡ç»“æœ
                evaluation_details = {
                    "num_layouts": num_layouts,
                    "alignment_score": alignment_score,
                    "overlap_score": overlap_score,
                    "avg_elements_per_layout": avg_elements,
                    "max_elements": max(element_counts),
                    "min_elements": min(element_counts),
                    "label_distribution": label_counts
                }
                
        except Exception as e:
            comments.append(f"å¸ƒå±€è¯„ä¼°è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
            process_status = False
            final_result_status = False
    
    output_data = {
        "Process": process_status,
        "Result": final_result_status,
        "TimePoint": time_point,
        "Comments": "\n".join(comments)
    }
    
    return output_data

def write_to_jsonl(file_path, data):
    """
    å°†å•æ¡ç»“æœä»¥ JSONL å½¢å¼è¿½åŠ åˆ°æ–‡ä»¶æœ«å°¾ï¼š
    æ¯è¿è¡Œä¸€æ¬¡ï¼Œappend ä¸€è¡Œ JSONã€‚
    """
    try:
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        with open(file_path, 'a', encoding='utf-8') as f:
            # å¢åŠ  default=strï¼Œé‡åˆ°æ— æ³•ç›´æ¥åºåˆ—åŒ–çš„ç±»å‹å°± str() å¤„ç†
            f.write(json.dumps(data, ensure_ascii=False, default=str) + '\n')
        print(f"âœ… ç»“æœå·²è¿½åŠ åˆ° JSONL æ–‡ä»¶: {file_path}")
    except Exception as e:
        print(f"âŒ å†™å…¥ JSONL æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='è¯„ä¼°å¸ƒå±€è´¨é‡å¹¶ç”ŸæˆæŠ¥å‘Š')
    parser.add_argument('--output', required=True, help='è¾“å…¥çš„å¸ƒå±€JSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--result', help='ç”¨äºå­˜å‚¨ JSONL ç»“æœçš„æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    print(f"å¼€å§‹è¯„ä¼°å¸ƒå±€ {args.output}")
    
    # è¯„ä¼°å¸ƒå±€
    evaluation_result = evaluate_layout(args.output)
    
    # è¾“å‡ºç»“æœ
    if args.result:
        write_to_jsonl(args.result, evaluation_result)
    
    print("\nè¯„ä¼°å®Œæˆ") 