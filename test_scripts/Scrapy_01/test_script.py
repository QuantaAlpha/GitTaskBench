import argparse
import json
import os
from datetime import datetime
from difflib import SequenceMatcher


def check_file_valid(file_path: str) -> bool:
    if not os.path.isfile(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return False
    if os.path.getsize(file_path) == 0:
        print(f"âŒ æ–‡ä»¶ä¸ºç©º: {file_path}")
        return False
    return True


def load_json_or_jsonl(file_path: str):
    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read().strip()
        if not content:
            return []

        # å°è¯•è§£æä¸º JSON array
        try:
            data = json.loads(content)
            if isinstance(data, list):
                return data
        except json.JSONDecodeError:
            pass

    # å¦åˆ™æŒ‰ JSONL å¤„ç†
    lines = []
    with open(file_path, "r", encoding="utf-8") as f:
        for i, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue
            try:
                item = json.loads(line)
                if isinstance(item, list):
                    lines.extend(item)
                else:
                    lines.append(item)
            except Exception as e:
                print(f"âŒ ç¬¬ {i} è¡Œ JSON è§£æå¤±è´¥: {line}")
                raise e
    return lines


def normalized_similarity(a: str, b: str) -> float:
    return SequenceMatcher(None, a.strip(), b.strip()).ratio()


def evaluate_scrapy_output(pred_path: str, truth_path: str, result_path: str = None) -> bool:
    threshold = 0.95
    process_success = check_file_valid(pred_path) and check_file_valid(truth_path)

    if not process_success:
        result = {
            "Process": False,
            "Result": False,
            "TimePoint": datetime.now().isoformat(),
            "comments": f"âŒ æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º: pred={pred_path}, truth={truth_path}"
        }
        if result_path:
            with open(result_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(result, ensure_ascii=False) + "\n")
        return False

    try:
        pred_lines = load_json_or_jsonl(pred_path)
        true_lines = load_json_or_jsonl(truth_path)

        if len(pred_lines) != len(true_lines):
            print(f"âš ï¸ æŠ“å–ç»“æœä¸æ ‡æ³¨æ•°é‡ä¸ä¸€è‡´ï¼ˆé¢„æµ‹ {len(pred_lines)} æ¡ï¼ŒçœŸå® {len(true_lines)} æ¡ï¼‰")

        total_fields = 0
        total_similarity = 0

        for pred, true in zip(pred_lines, true_lines):
            for field in ["author", "text"]:
                pred_val = str(pred.get(field, ""))
                true_val = str(true.get(field, ""))
                sim = normalized_similarity(pred_val, true_val)
                total_similarity += sim
                total_fields += 1

        avg_similarity = total_similarity / total_fields if total_fields else 0
        result_passed = avg_similarity >= threshold

        print(f"ğŸ“Š å¹³å‡å­—æ®µç›¸ä¼¼åº¦ (ç¼–è¾‘è·ç¦»ç›¸ä¼¼åº¦): {avg_similarity:.2%}")
        print("âœ… æå–æœ‰æ•ˆï¼Œç›¸ä¼¼åº¦ >= 95%" if result_passed else "âŒ æå–å¤±è´¥")

        if result_path:
            result = {
                "Process": True,
                "Result": result_passed,
                "TimePoint": datetime.now().isoformat(),
                "comments": f"å¹³å‡å­—æ®µç›¸ä¼¼åº¦: {avg_similarity:.4f}ï¼Œ{'æ»¡è¶³' if result_passed else 'ä¸æ»¡è¶³'} 95% é˜ˆå€¼"
            }
            with open(result_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(result, ensure_ascii=False) + "\n")

        return result_passed

    except Exception as e:
        print(f"âŒ è¿è¡Œå¼‚å¸¸: {e}")
        if result_path:
            result = {
                "Process": True,
                "Result": False,
                "TimePoint": datetime.now().isoformat(),
                "comments": f"è¿è¡Œå¼‚å¸¸: {str(e)}"
            }
            with open(result_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(result, ensure_ascii=False) + "\n")
        return False


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="è¯„ä¼° Scrapy æŠ“å–ç»“æœçš„å­—æ®µçº§ç›¸ä¼¼åº¦")
    parser.add_argument("--output", type=str, required=True, help="é¢„æµ‹ç»“æœï¼ˆJSON/JSONLï¼‰è·¯å¾„")
    parser.add_argument("--groundtruth", type=str, required=True, help="æ ‡æ³¨æ•°æ®ï¼ˆJSON/JSONLï¼‰è·¯å¾„")
    parser.add_argument("--result", type=str, required=False, help="ä¿å­˜ç»“æœçš„JSONLæ–‡ä»¶è·¯å¾„")

    args = parser.parse_args()
    success = evaluate_scrapy_output(args.output, args.groundtruth, args.result)

